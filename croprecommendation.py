# -*- coding: utf-8 -*-
"""CropRecommendation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SR50lMTBTH8UR0dYOgQVTlq4Ku7jUZXp
"""

#importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#loading the dataset
df = pd.read_csv('/content/Crop_recommendation.csv')

df.head()

df.shape

df.info()

df.isnull().sum()

df.duplicated().sum()

df.describe()

df_numeric = df.drop('label', axis=1)
df_numeric.corr()

sns.heatmap(df_numeric.corr(), annot=True)

df.label.value_counts()

df['label'].unique()

df['label'].unique().size

sns.displot(df['P'])
plt.show()

sns.displot(df['N'])
plt.show()

#encoding the labels
crop_dict = {
    'rice': 0,
    'maize': 1,
    'chickpea': 2,
    'kidneybeans': 3,
    'pigeonpeas': 4,
    'mothbeans': 5,
    'mungbean': 6,
    'blackgram': 7,
    'lentil': 8,
    'pomegranate':9,
    'banana': 10,
    'mango': 11,
    'grapes': 12,
    'watermelon': 13,
    'muskmelon': 1,
    'apple': 15,
    'orange': 16,
    'papaya': 17,
    'coconut': 18,
    'cotton': 19,
    'jute': 20,
    'coffee': 21
}

df['label'] = df['label'].map(crop_dict)
df.head()

df['label'].unique()

df.label.value_counts()

X = df.drop('label', axis=1)
Y = df['label']

X.head()

Y.head()

#train-test-split
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

X_train.shape

X_test.shape

#using minmax for scaling the features
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train

#standardization of our dataset
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
sc.fit(X_train)
X_train = sc.transform(X_train)
X_test = sc.transform(X_test)

X_train

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.metrics import accuracy_score

models = {
    'LogisticRegression': LogisticRegression(),
    'GaussianNB':GaussianNB(),
    'SVC':SVC(),
    'KNeighborsClassifier':KNeighborsClassifier(),
    'DecisionTreeClassifier':DecisionTreeClassifier(),
    'ExtraTreeClassifier':ExtraTreeClassifier(),
    'RandomForestClassifier':RandomForestClassifier(),
    'BaggingClassifier':BaggingClassifier(),
    'GradientBoostingClassifier':GradientBoostingClassifier(),
    'AdaBoostClassifier':AdaBoostClassifier()
}

for name, model in models.items():
    model.fit(X_train, Y_train)
    y_pred = model.predict(X_test)
    score = accuracy_score(Y_test, y_pred)
    print(f"{name} model with accuracy: {score}")

randclf = RandomForestClassifier()
randclf.fit(X_train, Y_train)
y_pred = randclf.predict(X_test)
accuracy_score(Y_test, y_pred)

df.columns

def recommendation(N,P,K,temperature,humidity,ph,rainfall):
    features = np.array([[N,P,K,temperature,humidity,ph,rainfall]])
    mx_features = scaler.fit_transform(features)
    sc_mx_features = scaler.fit_transform(mx_features)
    prediction = randclf.predict(sc_mx_features).reshape(1,-1)
    return prediction[0]

df.head()

N=90
P= 42
K= 43
temperature= 20.879744
humidity=82.002744
ph=6.502985
rainfall=202.935536

predict = recommendation(N,P,K,temperature,humidity,ph,rainfall)

predict

import pickle
pickle.dump(randclf, open('model.pkl', 'wb'))
pickle.dump(scaler, open('minmaxscaler.pkl', 'wb'))
pickle.dump(sc, open('standscaler.pkl', 'wb'))

